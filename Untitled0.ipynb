{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanyuyu/-/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wam9sriSck_R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DGfDiYyJdBvl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "f9c73038-9c07-4a8f-c489-bc2d63f6ad98"
      },
      "cell_type": "code",
      "source": [
        "# 搭建深度学习模型\n",
        "# 导入库\n",
        "# 自动驾驶模型真实道路模拟行驶\n",
        "import keras\n",
        "import tensorflow\n",
        "import sys\n",
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
        "from keras.models import load_model, Model, Input\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from keras.optimizers import Adam, SGD\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# 全局变量\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 120, 160, 3\n",
        "INPUT_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
        "\n",
        "\n",
        "\n",
        "# step1,载入数据，并且分割为训练和验证集\n",
        "# 问题，数据集太大了，已经超过计算机内存\n",
        "def load_data():\n",
        "    # load\n",
        "    image_array = np.zeros((1, 120, 160, 3))               # 初始化\n",
        "    label_array = np.zeros((1, 5), 'float')\n",
        "    training_data = glob.glob('training_data_npz/*.npz')\n",
        "    # 匹配所有的符合条件的文件，并将其以list的形式返回。\n",
        "    print(\"匹配完成。开始读入\")\n",
        "    print(\"一共%d轮\", len(training_data))\n",
        "\n",
        "    # if no data, exit，容错判断\n",
        "    if not training_data:\n",
        "        print(\"No training data in directory, exit\")\n",
        "        sys.exit()\n",
        "    i = 0\n",
        "    for single_npz in training_data:\n",
        "        with np.load(single_npz) as data:\n",
        "            print(data.keys())\n",
        "            i = i + 1\n",
        "            print(\"在打印关键值\", i)\n",
        "            train_temp = data['train_imgs']\n",
        "            train_labels_temp = data['train_labels']\n",
        "        image_array = np.vstack((image_array, train_temp)) # 把文件读取都放入，内存\n",
        "        label_array = np.vstack((label_array, train_labels_temp))\n",
        "        print(\"第%d轮完成\", i)\n",
        "    print(\"循环完了\")\n",
        "    X = image_array[1:, :]\n",
        "    y = label_array[1:, :]\n",
        "    print('Image array shape: ' + str(X.shape))\n",
        "    print('Label array shape: ' + str(y.shape))\n",
        "    print(np.mean(X))\n",
        "    print(np.var(X))\n",
        "\n",
        "    # now we can split the data into a training (80), testing(20), and validation set\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "    return X_train, X_valid, y_train, y_valid\n",
        "\n",
        "\n",
        "# step2 建立模型\n",
        "def build_model(keep_prob):\n",
        "    print(\"开始编译模型\")\n",
        "    model = Sequential()\n",
        "    model.add(Lambda(lambda x: (x/102.83 - 1), input_shape = INPUT_SHAPE))\n",
        "    model.add(Conv2D(24, (5, 5), activation='elu', strides=(2, 2)))\n",
        "    model.add(Conv2D(36, (5, 5), activation='elu', strides=(2, 2)))\n",
        "    model.add(Conv2D(48, (5, 5), activation='elu', strides=(2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3),activation='elu'))\n",
        "    model.add(Conv2D(64, (3, 3),activation='elu'))\n",
        "    model.add(Dropout(keep_prob))  # Dropout将在训练过程中每次更新参数时随机断开一定百分比（p）的输入神经元连接\n",
        "    model.add(Flatten())\n",
        "    #model.add(Dense(500, activation='elu'))\n",
        "    model.add(Dense(250, activation='elu'))\n",
        "    #model.add(Dense(50, activation='elu'))\n",
        "    model.add(Dense(5))\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# step3 训练模型\n",
        "def train_model(model, learning_rate, nb_epoch, samples_per_epoch,\n",
        "                batch_size, X_train, X_valid, y_train, y_valid):\n",
        "    # 值保存最好的模型存下来\n",
        "    checkpoint = ModelCheckpoint('model-{epoch:03d}.h5',\n",
        "                                 monitor='val_loss',\n",
        "                                 verbose=0,\n",
        "                                 save_best_only=True,\n",
        "                                 mode='min')\n",
        "    # EarlyStopping patience：当earlystop被激活（如发现loss相比上一个epoch训练没有下降），\n",
        "    # 则经过patience个epoch后停止训练。\n",
        "    # mode：‘auto’，‘min’，‘max’之一，在min模式下，如果检测值停止下降则中止训练。在max模式下，当检测值不再上升则停止训练。\n",
        "    early_stop = EarlyStopping(monitor='loss', min_delta=.0005, patience=10,\n",
        "                               verbose=1, mode='min')\n",
        "    tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=20, write_graph=True,write_grads=True,\n",
        "                              write_images=True, embeddings_freq=0, embeddings_layer_names=None,\n",
        "                              embeddings_metadata=None)\n",
        "    # 编译神经网络模型，loss损失函数，optimizer优化器， metrics列表，包含评估模型在训练和测试时网络性能的指标\n",
        "    model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
        "    # 训练神经网络模型，batch_size梯度下降时每个batch包含的样本数，epochs训练多少轮结束，\n",
        "    # verbose是否显示日志信息，validation_data用来验证的数据集\n",
        "    model.fit_generator(batch_generator(X_train, y_train, batch_size),\n",
        "                        steps_per_epoch=samples_per_epoch/batch_size,\n",
        "                        epochs = nb_epoch,\n",
        "                        max_queue_size=1,\n",
        "                        validation_data=batch_generator(X_valid, y_valid, batch_size),\n",
        "                        validation_steps=len(X_valid)/batch_size,\n",
        "                        callbacks=[tensorboard, checkpoint, early_stop],\n",
        "                        verbose=2)\n",
        "\n",
        "# step4\n",
        "# 可以一个batch一个batch进行训练，CPU和GPU同时开工\n",
        "def batch_generator(X, y, batch_size):\n",
        "    images = np.empty([batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS])\n",
        "    steers = np.empty([batch_size, 5])\n",
        "    while True:\n",
        "        i = 0\n",
        "        for index in np.random.permutation(X.shape[0]):\n",
        "            images[i] = X[index]\n",
        "            steers[i] = y[index]\n",
        "            i += 1\n",
        "            if i == batch_size:\n",
        "                break\n",
        "        yield (images, steers)\n",
        "\n",
        "\n",
        "# step5 评估模型\n",
        "#def evaluate(x_test, y_test):\n",
        "    #score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    #print('Test loss:', score[0])\n",
        "    #print('Test accuracy:', score[1])\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 打印出超参数\n",
        "\n",
        "    print('-'*30)\n",
        "    print('parameters')\n",
        "    print('-'*30)\n",
        "\n",
        "\n",
        "    keep_prob = 0.5\n",
        "    learning_rate = 0.0001\n",
        "    nb_epoch = 100\n",
        "    samples_per_epoch = 3000\n",
        "    batch_size = 30\n",
        "\n",
        "    print('keep_prob = ', keep_prob)\n",
        "    print('learning_rate = ', learning_rate)\n",
        "    print('nb_epoch = ', nb_epoch)\n",
        "    print('samples_per_epoch = ', samples_per_epoch)\n",
        "    print('batch_size = ', batch_size)\n",
        "    print('-' * 30)\n",
        "\n",
        "    # 开始载入数据\n",
        "    data = load_data()\n",
        "    print(\"数据加载完毕\")\n",
        "    # 编译模型\n",
        "    model = build_model(keep_prob)\n",
        "    # 在数据集上训练模型，保存成model.h5\n",
        "    train_model(model, learning_rate, nb_epoch, samples_per_epoch, batch_size, *data)\n",
        "    print(\"模型训练完毕\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "parameters\n",
            "------------------------------\n",
            "keep_prob =  0.5\n",
            "learning_rate =  0.0001\n",
            "nb_epoch =  100\n",
            "samples_per_epoch =  3000\n",
            "batch_size =  30\n",
            "------------------------------\n",
            "匹配完成。开始读入\n",
            "一共%d轮 0\n",
            "No training data in directory, exit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}